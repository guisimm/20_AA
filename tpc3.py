# -*- coding: utf-8 -*-
"""TPC3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MUvdtFHQUSYRgnNTcXvuAc8MfaWAMInZ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pickle
from sklearn.metrics import explained_variance_score, mean_squared_error, max_error, mean_absolute_error
from scipy.stats import pearsonr
from sklearn.svm import SVR
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import f1_score, classification_report, confusion_matrix, matthews_corrcoef
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import Ridge
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import Lasso

def printRegStatistics(truth, preds):
    print("The RVE is: ", explained_variance_score(truth, preds))
    print("The rmse is: ", mean_squared_error(truth, preds, squared=False))
    corr, pval = pearsonr(truth, preds)
    print("The Correlation Score is is: %6.4f (p-value=%e)\n"%(corr,pval))
    print("The Maximum Error is is: ", max_error(truth, preds))
    print("The Mean Absolute Error is: ", mean_absolute_error(truth, preds))

from google.colab import drive
drive.mount('/content/drive')
#Este passo existe pois usamos o Google colab

caminho_gui ='/content/drive/MyDrive/drd2_data.pickle'

X_train, X_ivs, y_train, col_names = pickle.load(open(caminho_gui, "rb"))

from sklearn.model_selection import train_test_split

# Dividir os dados de treino em subconjuntos de treino e teste
X_train_sub, X_test, y_train_sub, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import SelectFromModel

# Inicializar o Random Forest Regressor
rf = RandomForestRegressor(random_state=0)

# Seleção de características
sel = SelectFromModel(rf)
sel.fit(X_train_sub, y_train_sub)

# Reduzir X_train_sub e X_test para as características selecionadas
X_train_selected = sel.transform(X_train_sub)
X_test_selected = sel.transform(X_test)

# Reduzir X_train_sub e X_test para as características selecionadas
X_train_selected = sel.transform(X_train_sub)
X_test_selected = sel.transform(X_test)

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
# Padronizar os dados antes de aplicar PCA
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_selected)
X_test_scaled = scaler.transform(X_test_selected)

# Aplicar PCA
pca = PCA(n_components=0.95)  # 95% de variação explicada
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Definir os parâmetros para testar
param_grid = {
    'C': [0.1, 1, 10, 100],  # Por exemplo, valores de penalidade
    'gamma': ['scale', 'auto'],  # Coeficiente de kernel para 'rbf', 'poly' e 'sigmoid'
    'kernel': ['rbf']  # Diferentes tipos de kernels
}

# Criar o objeto GridSearchCV
grid_search = GridSearchCV(SVR(), param_grid, cv=3, scoring='r2', verbose=2, n_jobs=-1)

# Ajustar o GridSearchCV
grid_search.fit(X_train_pca, y_train_sub)

# Obter o melhor modelo encontrado pelo GridSearchCV
best_model = grid_search.best_estimator_

# Avaliar o melhor modelo
y_pred_svr = best_model.predict(X_test_pca)

printRegStatistics(y_test,y_pred_svr)
print(grid_search.best_params_)

# Definir os parâmetros para testar no Random Forest
param_grid_rf = {
    'n_estimators': [100, 200, 300],  # Número de árvores
    'max_features': ['auto'],  # Número máximo de características consideradas para dividir um nó
    'max_depth': [10, 20, 30],  # Profundidade máxima da árvore
    # Adicionar outros parâmetros conforme necessário
}
# Criar o objeto GridSearchCV para Random Forest
grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=3, scoring='r2', verbose=2, n_jobs=-1)

# Ajustar o GridSearchCV ao conjunto de treinamento
grid_search_rf.fit(X_train_pca, y_train_sub)
# Obter o melhor modelo encontrado pelo GridSearchCV
best_rf_model = grid_search_rf.best_estimator_

# Avaliar o melhor modelo
y_pred_rf = best_rf_model.predict(X_test_pca)
printRegStatistics(y_test,y_pred_rf)

lr_model = LinearRegression()
lr_model.fit(X_train_pca, y_train_sub)
y_pred_lr = lr_model.predict(X_test_pca)
printRegStatistics(y_test,y_pred_lr)

# Define a range of alpha values to test
alpha_values = np.logspace(-4, 4, 500)

# Atualizar o espaço de parâmetros para o GridSearchCV
param_grid_ridge = {'alpha': alpha_values}

#Criar o objeto GridSearchCV para Ridge
grid_search_ridge = GridSearchCV(Ridge(), param_grid_ridge, cv=3, scoring='r2', verbose=2, n_jobs=-1)

# Ajustar o GridSearchCV ao conjunto de treinamento
grid_search_ridge.fit(X_train_pca, y_train_sub)

# Obter o melhor modelo e alpha encontrado pelo GridSearchCV para Ridge
best_ridge_model = grid_search_ridge.best_estimator_
y_pred_ridge = best_ridge_model.predict(X_test_pca)
printRegStatistics(y_test,y_pred_ridge)

# Define a range of alpha values to test
alpha_values = np.logspace(-4, 4, 500)

# Atualizar o espaço de parâmetros para o GridSearchCV
param_grid_lasso = {'alpha': alpha_values}

# Criar o objeto GridSearchCV para Lasso
grid_search_lasso = GridSearchCV(Lasso(), param_grid_lasso, cv=3, scoring='r2', verbose=2, n_jobs=-1)

# Ajustar o GridSearchCV ao conjunto de treinamento
grid_search_lasso.fit(X_train_pca, y_train_sub)

# Obter o melhor modelo e alpha encontrado pelo GridSearchCV para Lasso
best_lasso_model = grid_search_lasso.best_estimator_
best_alpha_lasso = grid_search_lasso.best_params_['alpha']
print(f"Melhor Alpha para Lasso: {best_alpha_lasso}")
# Avaliar o melhor modelo Lasso
y_pred_lasso = best_lasso_model.predict(X_test_pca)
printRegStatistics(y_test,y_pred_lasso)

from sklearn.ensemble import AdaBoostRegressor

# Definir os parâmetros para testar no AdaBoost
param_grid_ada = {
    'n_estimators': [50, 100, 200],  # Número de modelos a serem construídos
    'learning_rate': [0.01, 0.1, 1],  # Contribuição de cada modelo para os pesos finais
    'loss': ['linear', 'square', 'exponential']  # Função de perda a ser usada
}

# Criar o objeto GridSearchCV para AdaBoost
grid_search_ada = GridSearchCV(AdaBoostRegressor(random_state=42), param_grid_ada, cv=3, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)

# Ajustar o GridSearchCV ao conjunto de treinamento
grid_search_ada.fit(X_train_pca, y_train_sub)

# Obter o melhor modelo encontrado pelo GridSearchCV
best_ada_model = grid_search_ada.best_estimator_

# Avaliar o melhor modelo
y_pred_ada = best_ada_model.predict(X_test_pca)
printRegStatistics(y_test,y_pred_ada)

from sklearn.ensemble import GradientBoostingRegressor
# Definir os parâmetros para testar no Gradient Boosting
param_grid_gb = {
    'n_estimators': [100, 200, 300],  # Número de árvores de reforço a serem construídas
    'learning_rate': [0.01, 0.1, 0.2],  # Taxa de aprendizagem
    'max_depth': [3, 4, 5],  # Profundidade máxima de cada árvore de regressão
    # Pode incluir outros parâmetros como 'min_samples_split', 'min_samples_leaf', etc.
}
# Criar o objeto GridSearchCV para Gradient Boosting
grid_search_gb = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid_gb, cv=3, scoring='r2', verbose=2, n_jobs=-1)

# Ajustar o GridSearchCV ao conjunto de treinamento
grid_search_gb.fit(X_train_pca, y_train_sub)

# Obter o melhor modelo encontrado pelo GridSearchCV
best_gb_model = grid_search_gb.best_estimator_

# Avaliar o melhor modelo
y_pred_gb = best_gb_model.predict(X_test_pca)
printRegStatistics(y_test,y_pred_gb)

from sklearn.tree import DecisionTreeRegressor
# Definir o espaço de parâmetros para testar na Árvore de Regressão
param_grid_tree = {
    'max_depth': [ 10, 15, 20,25],  # Profundidade máxima da árvore
    'min_samples_leaf': [1, 2, 4],       # Número mínimo de amostras necessárias em um nó folha
}
# Criar o objeto GridSearchCV para Árvore de Regressão
grid_search_tree = GridSearchCV(DecisionTreeRegressor(random_state=42), param_grid_tree, cv=3, scoring='r2', verbose=2, n_jobs=-1)

# Ajustar o GridSearchCV ao conjunto de treinamento
grid_search_tree.fit(X_train_pca, y_train_sub)
# Obter o melhor modelo encontrado pelo GridSearchCV
best_tree_model = grid_search_tree.best_estimator_

# Avaliar o melhor modelo
y_pred_tree = best_tree_model.predict(X_test_pca)
printRegStatistics(y_test,y_pred_tree)

from sklearn.neural_network import MLPRegressor
# Definir o espaço de parâmetros para testar
param_grid_mlp = {
    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],  # Tamanhos das camadas ocultas
    'alpha': [0.0001, 0.001, 0.01],  # Termo de regularização L2 (penalidade)
    'learning_rate_init': [0.001, 0.01],  # Taxa de aprendizado inicial
}
# Criar o objeto GridSearchCV para MLP
grid_search_mlp = GridSearchCV(MLPRegressor(max_iter=1000, random_state=42), param_grid_mlp, cv=3, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)

# Ajustar o GridSearchCV ao conjunto de treinamento
grid_search_mlp.fit(X_train_pca, y_train_sub)
# Obter o melhor modelo encontrado pelo GridSearchCV
best_mlp_model = grid_search_mlp.best_estimator_

# Avaliar o melhor modelo
y_pred_mlp = best_mlp_model.predict(X_test_pca)
printRegStatistics(y_test,y_pred_mlp)

best_model.fit(X_train,y_train)
y_preds=best_model.predict(X_ivs)
print(y_preds)

below_zero = (y_preds < 0).sum()
above_one = (y_preds > 1).sum()
print(f"Número de elementos abaixo de 0: {below_zero}, acima de 1: {above_one}")

#guardando o ficheiro de previsões
with open("y_preds.txt", "w") as file:
    for pred in y_preds:
        file.write(f"{pred}\n")

from google.colab import files

# Fazer o download do arquivo
files.download('y_preds.txt')